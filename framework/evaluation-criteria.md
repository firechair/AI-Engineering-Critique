# Evaluation Criteria

This document defines the standard dimensions used for evaluating AI outputs in this repository.

## 1. Code Review Dimensions

### Correctness
- **Definition**: Does the code work as intended?
- **Key Checks**: Logic errors, bugs, syntax issues, functional requirements.

### Code Quality
- **Definition**: Is the code maintainable?
- **Key Checks**: Naming conventions, modularity, DRY (Don't Repeat Yourself), comments.

### Best Practices
- **Definition**: Does it follow language idioms?
- **Key Checks**: PEP8 (Python), modern syntax, safety patterns.

### Edge Cases
- **Definition**: Is it robust?
- **Key Checks**: Null inputs, empty lists, boundary values, error handling.

### Performance
- **Definition**: Is it efficient?
- **Key Checks**: Time complexity, memory usage, database query optimization.

## 2. Writing & Analysis Dimensions

### Accuracy
- **Definition**: Is it true?
- **Key Checks**: Hallucinations, factual errors, reasoning validity.

### Clarity
- **Definition**: Is it easy to read?
- **Key Checks**: Jargon usage, sentence structure, flow.

### Completeness
- **Definition**: Did it answer the prompt?
- **Key Checks**: All sub-questions answered, sufficient detail.

### Structure
- **Definition**: Is it organized?
- **Key Checks**: Headings, lists, logical progression.

### Style
- **Definition**: Is the tone right?
- **Key Checks**: Professionalism, engagement, persona match.
