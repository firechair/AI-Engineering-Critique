# Research & Data Analysis Evaluation Rubric

## Overview

This document defines the evaluation framework for assessing AI-generated research summaries, data analysis, factual reports, and investigative content across multiple quality dimensions. Each dimension is rated on a 3-point scale, and responses receive an overall quality assessment based on the combined ratings.

---

## Rating Scale

All dimensions use the following rating scale:

- **3 - No Issues**: Response meets all criteria with no identifiable problems
- **2 - Minor Issues**: Response has small problems that don't significantly impact usefulness (up to 3 minor mistakes are still considered minor issues)
- **1 - Major Issues**: Response has significant problems that severely impact usefulness

---

## Evaluation Dimensions

### 1. Factual Accuracy & Evidence

**Definition**: Correctness of facts, quality of sources, and evidence-based reasoning.

#### What to Evaluate:
- Are all facts verifiable and correct?
- Are there any hallucinations or fabrications?
- Are claims supported by credible sources?
- Are data and statistics used correctly?
- Is proper attribution and citation provided?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Impeccable accuracy, all claims well-sourced and evidence-based throughout. | - All facts verified and correct<br>- No fabrications<br>- Credible sources cited<br>- Statistics accurate<br>- Proper citations |
| **2 - Minor Issues** | Mostly accurate with minor unsupported claims or attribution gaps. | - One minor factual imprecision<br>- Some claims lack citations<br>- Minor source quality issues<br>- Mostly correct statistics |
| **1 - Major Issues** | Contains significant errors, hallucinations, or fundamentally unsupported claims. | - Fabricated data or sources<br>- Major factual Errors<br>- Uncited critical claims<br>- Misused statistics<br>- No attribution |

#### Source Quality Hierarchy:
1. **Primary sources**: Original research, raw data
2. **Peer-reviewed**: Academic journals, reviewed publications
3. **Authoritative**: Government data, industry reports
4. **Secondary**: News outlets, reputable blogs
5. **Questionable**: Uncited claims, opinion pieces

#### Best Practices:
- Verify factual claims against authoritative sources
- Check dates (information may be outdated)
- Validate statistical interpretations
- Ensure proper citation format

---

### 2. Analytical Rigor

**Definition**: Quality of analysis, logical reasoning, critical thinking, and depth of insights.

#### What to Evaluate:
- Is reasoning sound and logical?
- Are analytical methods appropriate?
- Are patterns and insights identified?
- Are logical fallacies avoided?
- Is there critical evaluation of evidence?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Rigorous analysis with sound reasoning and insightful conclusions. | - Logical reasoning throughout<br>- Appropriate methods used<br>- Key insights identified<br>- No logical fallacies<br>- Critical thinking evident |
| **2 - Minor Issues** | Adequate analysis with minor logical gaps or superficial reasoning. | - Mostly sound reasoning<br>- Some analytical shortcuts<br>- Limited depth in parts<br>- Minor logical inconsistencies<br>- Some insights missed |
| **1 - Major Issues** | Weak analysis with flawed reasoning, superficial thinking, or logical errors. | - Flawed logical reasoning<br>- Inappropriate methods<br>- No real insights<br>- Logical fallacies present<br>- Superficial analysis |

#### Common Logical Fallacies to Avoid:
- Correlation implies causation
- Cherry-picking data
- Hasty generalization
- False dichotomy
- Confirmation bias

---

### 3. Completeness & Thoroughness

**Definition**: Comprehensive coverage of the topic with sufficient depth of investigation.

#### What to Evaluate:
- Are all aspects of the research question addressed?
- Is there sufficient depth of investigation?
- Are multiple perspectives considered?
- Are limitations and gaps acknowledged?
- Is literature/data coverage comprehensive?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Thorough and comprehensive coverage with all aspects well-investigated. | - Research question fully addressed<br>- Deep investigation<br>- Multiple perspectives<br>- Limitations acknowledged<br>- Comprehensive coverage |
| **2 - Minor Issues** | Adequate coverage with some gaps or areas needing more depth. | - Main aspects covered<br>- Some superficial sections<br>- Limited perspectives<br>- Some gaps in coverage<br>- Minor limitations unmentioned |
| **1 - Major Issues** | Incomplete and superficial, missing key aspects of the investigation. | - Research question partially addressed<br>- Very shallow investigation<br>- Single perspective only<br>- Major gaps throughout<br>- Critical aspects missing |

---

### 4. Objectivity & Bias

**Definition**: Neutrality, balanced presentation, and absence of bias in analysis and reporting.

#### What to Evaluate:
- Is information presented objectively?
- Are multiple viewpoints acknowledged?
- Are facts distinguished from opinions?
- Is bias minimized in interpretation?
- Is there transparency about limitations and assumptions?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Highly objective, balanced, and unbiased presentation throughout. | - Objective presentation<br>- Multiple viewpoints shown<br>- Clear fact vs opinion<br>- No apparent bias<br>- Transparent about limits |
| **2 - Minor Issues** | Generally objective with minor bias or imbalanced presentation. | - Mostly objective<br>- Some viewpoints favored<br>- Occasional opinion as fact<br>- Minor bias detectable<br>- Some assumptions unstated |
| **1 - Major Issues** | Biased, one-sided presentation or opinions presented as facts. | - Clearly biased presentation<br>- Single viewpoint<br>- Opinions stated as facts<br>- Major bias throughout<br>- No transparency on limits |

#### Objectivity Checklist:
- [ ] Multiple perspectives presented
- [ ] Facts clearly separated from interpretation
- [ ] Balanced coverage of different viewpoints
- [ ] Limitations acknowledged
- [ ] No loaded language

---

### 5. Data Presentation & Visualization

**Definition**: Clarity and effectiveness of data presentation, including tables, charts, and statistical communication.

#### What to Evaluate:
- Is data presented clearly and accurately?
- Is there appropriate use of tables, charts, or statistics?
- Do visualizations enhance understanding?
- Is data interpretation correct?
- Are key findings highlighted effectively?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Excellent data presentation that is clear, accurate, and insightful. | - Clear data presentation<br>- Appropriate visualizations<br>- Enhances understanding<br>- Correct interpretation<br>- Key findings highlighted |
| **2 - Minor Issues** | Adequate presentation with minor clarity issues or suboptimal visualization choices. | - Data somewhat clear<br>- Visualizations adequate<br>- Minor interpretation issues<br>- Some findings not highlighted<br>- Could be clearer |
| **1 - Major Issues** | Poor, confusing, or misleading data presentation. | - Confusing presentation<br>- Inappropriate/no visualizations<br>- Misleading charts<br>- Incorrect interpretation<br>- Key findings buried |

#### Visualization Best Practices:
- Choose appropriate chart types
- Label axes and units clearly
- Use consistent scales
- Avoid misleading representations
- Highlight key insights

---

### 6. Structure & Organization

**Definition**: Logical organization of research findings, arguments, and supporting evidence.

#### What to Evaluate:
- Is there clear structure (intro, methods, findings, conclusion)?
- Is there logical flow of information?
- Is it easy to navigate and reference?
- Is there appropriate use of sections and headings?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Excellently organized with clear structure and easy navigation. | - Clear research structure<br>- Logical information flow<br>- Easy to navigate<br>- Well-organized sections<br>- Appropriate headings |
| **2 - Minor Issues** | Adequately organized with minor structural issues or navigation challenges. | - Basic structure present<br>- Some organizational gaps<br>- Navigation adequate<br>- Could use better sections<br>- Some flow issues |
| **1 - Major Issues** | Poorly organized, making it hard to follow or find information. | - No clear structure<br>- Illogical flow<br>- Hard to navigate<br>- Poor section organization<br>- Confusing layout |

---

### 7. Clarity & Accessibility

**Definition**: How clearly research is communicated to the target audience.

#### What to Evaluate:
- Is writing clear and understandable?
- Are technical terms explained when needed?
- Is content accessible to target audience?
- Are key takeaways clearly stated?

#### Rating Guidelines:

| Rating | Description | Examples |
|--------|-------------|----------|
| **3 - No Issues** | Crystal clear, accessible, and well-explained for target audience. | - Clear writing<br>- Terms explained<br>- Accessible to audience<br>- Takeaways explicit<br>- Easy to understand |
| **2 - Minor Issues** | Generally clear with some confusing parts or unexplained terms. | - Mostly clear<br>- Some jargon unexplained<br>- Generally accessible<br>- Takeaways present but unclear<br>- Some confusion |
| **1 - Major Issues** | Confusing, inaccessible, or poorly explained for intended audience. | - Unclear writing<br>- Heavy unexplained jargon<br>- Not accessible<br>- No clear takeaways<br>- Very confusing |

---

## Overall Quality Assessment

After rating individual dimensions, assign an overall quality score:

| Overall Rating | Criteria |
|----------------|----------|
| **Excellent** | All dimensions rated "No Issues". Research is publication-quality. |
| **Discrete** | At most 1 dimension has "Minor Issues". High-quality research with minor gaps. |
| **Sufficient** | 2-3 dimensions have "Minor Issues". Solid foundation but needs refinement. |
| **Inadequate** | 1 dimension has "Major Issues" OR 4+ dimensions have "Minor Issues". Significant quality problems. |
| **Unacceptable** | 2+ dimensions have "Major Issues". Fundamentally flawed research. |

---

## Response Comparison Methodology

When comparing two research responses:

### Step 1: Individual Assessment
Rate each response independently across all dimensions.

### Step 2: Prioritize Dimensions

- **Critical**: Factual Accuracy & Evidence, Analytical Rigor
- **Important**: Completeness & Thoroughness, Objectivity & Bias
- **Nice-to-have**: Data Presentation, Structure, Clarity

### Step 3: Preference Ranking

| Score | Meaning |
|-------|---------|
| **+2** | Response A significantly better |
| **+1** | Response A somewhat better |
| **0** | Roughly equivalent |
| **-1** | Response B somewhat better |
| **-2** | Response B significantly better |

---

## Common Pitfalls to Avoid

### When Researching:
- Don't rely on single sources
- Don't confuse correlation with causation
- Don't cherry-pick supporting data
- Don't ignore contradictory evidence
- Don't present opinions as facts

### When Evaluating:
- Don't accept claims without verification
- Don't overlook citation gaps
- Don't ignore methodological weaknesses
- Verify statistics and data interpretations

---

## Use Case Examples

**Perfect for evaluating**:
- Research summaries
- Data analysis reports
- Literature reviews
- Market research
- Statistical analysis
- Factual investigations
- Meta-analyses

**Not ideal for**:
- Code (use Coding Rubric)
- Documentation (use Technical Writing Rubric)
- System design (use Architecture Rubric)
- Creative content (use Creative Writing Rubric)

---

## Version History

- **v1.0** - Initial comprehensive research & analysis rubric following coding rubric v1.1 format

---

*This rubric guide is designed for the AI Engineering Critique repository to demonstrate systematic evaluation methodology for AI-generated research and data analysis.*
